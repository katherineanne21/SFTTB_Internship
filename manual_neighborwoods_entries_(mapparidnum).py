# -*- coding: utf-8 -*-
"""Manual_NeighborWoods_Entries_(MAPParIDNum).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eh5DDLlRNwkKEJh1fwQAZ29rQkbYA_LE

### Values to Change
"""

# Enter the Map Parcel ID Number and source
MAP_PAR_ID = '1812388000'
source_type = 'Tree Alliance'

"""### Prep Workspace"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Import required modules
import pandas as pd
import numpy as np
import gspread
import string
from oauth2client.service_account import ServiceAccountCredentials

# Define the scope
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]

# Provide the path to the JSON file
creds = ServiceAccountCredentials.from_json_keyfile_name('/content/drive/Shareddrives/SFTT Shared Drive/NeighborWoods Data Management/enhanced-keel-424914-m2-7c2e82d072b9.json', scope)

# Authorize the clientsheet
client = gspread.authorize(creds)

"""### Read In Data"""

# Read in the merged geodatabases

file_path = '/content/drive/Shareddrives/SFTT Shared Drive/NeighborWoods Data Management/Merged_Geodatabse.csv'

dtype_spec = {
    'addr_str': str,
    'addr_num': str,
    'MAP_PAR_ID': str,
    'muni': str,
    'site_addr': str,
    'addr_zip': str,
    'tes': str,
    'LU_Recode_': str,
}

merged_df = pd.read_csv(file_path, dtype=dtype_spec, low_memory=False)

# New Tree Planting Progress Database
TPP_url = 'https://docs.google.com/spreadsheets/d/15TbiooJKm0yN6qaZsuhguYETzz_M3g4UM5RdwW_Zn3E/edit?gid=0#gid=0'
TPP_Sheets = client.open_by_url(TPP_url)

TPP_Sheet4 = TPP_Sheets.worksheet("Website Sign Ups")

TPP_Website = TPP_Sheet4.get_all_values()

TPP_Website_df = pd.DataFrame(TPP_Website[1:], columns = TPP_Website[0])

"""###Linking Data

"""

Full_df = merged_df[merged_df['MAP_PAR_ID'] == MAP_PAR_ID].copy()

"""###Create columns"""

# Add in website for all rows under the Source column
Full_df['Source'] = source_type

# Change City column to first letter capitals
Full_df['CITY'] = Full_df['CITY'].str.title()

# Create a list of acceptable neighborhoods
neighborhood_list = ['Dorchester','Hyde Park', 'Roxbury', 'Mattapan']

# Add Available Area (sqm) column
Full_df['Lot Area (sqm)'] = (Full_df['sqm_imperv'] * 100)/ Full_df['pct_imperv']
Full_df['Available Area (sqm)'] = Full_df['Lot Area (sqm)'] - Full_df['sqm_imperv']

# Print Full_df columns
print(Full_df.columns.tolist())

"""###Rename columns"""

# Choose columns to save
selected_columns = [
    'Source',
    'MAP_PAR_ID',
    'muni',
    'site_addr',
    'addr_str',
    'addr_num',
    'addr_zip',
    'CanopyPerc',
    'CITY',
    'Lot Area (sqm)',
    'pct_imperv',
    'tes',
    'PrioZone',
    'HisDis (Historical Disinvestment)',
    'EJ Flag',
    'EJ #',
    'Available Area (sqm)',
    'HisDis Letter',
    'LU_Recode_',
    'ID_Num',
    'sqm_imperv']

new_Full_df = Full_df[selected_columns].copy()

# Rename columns
new_column_names = {
    'Source': 'Source',
    'ID_Num': 'ID_Num',
    'MAP_PAR_ID': 'Map Parcel ID',
    'muni': 'Municipality',
    'site_addr': 'Site Address (ArcGIS)',
    'addr_str': 'Street Name (ArcGIS)',
    'addr_num': 'Street Number (ArcGIS)',
    'addr_zip': 'Street Zip (ArcGIS)',
    'sqm_imperv': 'Impervious Area (sqm)',
    'CanopyPerc': 'Canopy Percentage (ArcGIS)',
    'CITY': 'Neighborhood (ArcGIS)',
    'Lot Area (sqm)': 'Lot Area (sqm)',
    'pct_imperv': 'Impervious Percentage (ArcGIS)',
    'tes': 'TES (Census block)',
    'PrioZone': 'UFPZ (Urban Forest Priority Zone)',
    'HisDis (Historical Disinvestment)': 'HisDis (Historical Disinvestment)',
    'EJ Flag': 'EJ Flag',
    'EJ #': 'EJ #',
    'Available Area (sqm)': 'Available Area (sqm)',
    'HisDis Letter': 'HisDis Letter',
    'LU_Recode_': 'Type of Property'
}

new_Full_df.rename(columns=new_column_names, inplace=True)

"""### Writing Data to Sheet"""

# Create a list of letters that rolls over to AA

multiple_letters_list = []
for i in range(1, 3):  # Go through once for singletons and a second time for doubles
        for letter in string.ascii_uppercase: # Repeat for each uppercase letter
            if i == 1:
                multiple_letters_list.append(letter)
            else:
                for letter2 in string.ascii_uppercase: # Repeat for each uppercase letter
                    multiple_letters_list.append(letter + letter2)

"""Back End"""

# List of columns to select for Back_End_df
selected_columns = [
    'ID_Num',
    'Source',
    'Site Address (ArcGIS)',
    'Street Number (ArcGIS)',
    'Street Name (ArcGIS)',
    'Neighborhood (ArcGIS)',
    'Municipality',
    'Street Zip (ArcGIS)',
    'Map Parcel ID',
    'UFPZ (Urban Forest Priority Zone)',
    'HisDis (Historical Disinvestment)',
    'HisDis Letter',
    'EJ Flag',
    'EJ #',
    'Available Area (sqm)',
    'Lot Area (sqm)',
    'Impervious Area (sqm)',
    'Impervious Percentage (ArcGIS)',
    'TES (Census block)',
    'Canopy Percentage (ArcGIS)',
    'Type of Property'
]

# Create Back End Dataframe
Back_End_df = new_Full_df[selected_columns].copy()

# Prep for writing to Google Sheet
sheet = client.open('Yardtree Planting Progress Database Neighborwoods')
Back_End = sheet.worksheet('Back End - NeighborWoods')

# Get data from Back End Sheet
existing_headers = Back_End.row_values(1)
existing_data = Back_End.get_all_values()

# Slice data to select the data from just the B:AE rows
start_col_index = 1  # Column B
end_col_index = 31  # Column AE

# Slice headers to include columns B through AE
existing_headers_slice = existing_headers[start_col_index:end_col_index + 1]

# Slice data to include columns B through AE
existing_data_slice = [row[start_col_index:end_col_index + 1] for row in existing_data]

existing_df = pd.DataFrame(existing_data_slice[1:], columns = existing_headers_slice)

# Get columns right
for col in existing_headers_slice:
    if col not in Back_End_df.columns:
        Back_End_df[col] = None

Back_End_df = Back_End_df[existing_headers_slice]

# Replace NaN and infinity values with None
Back_End_df = Back_End_df.replace({np.nan: None, np.inf: None, -np.inf: None})

# Convert DataFrame to a list of lists, excluding the header
data_list = Back_End_df.values.tolist()

# Find the first empty row in the "Input Date" column
input_date_col_idx = existing_headers_slice.index("Input Date")
start_row = next((idx for idx, row in enumerate(existing_data[1:], start=2) if not row[input_date_col_idx]), len(existing_data) + 1)

# Prepare the range for updating (starting at column B)
start_col = 'B'
end_col = multiple_letters_list[len(data_list[0])]
range_to_update = f'{start_col}{start_row}:{end_col}{start_row + len(data_list) - 1}'

# Append the data to the Google Sheet without the header
Back_End.update(range_to_update, data_list, value_input_option='USER_ENTERED')

"""Front Facing"""

# List of columns to select for Front_Facing_df
selected_columns = [
    'ID_Num',
    'Source',
    'Neighborhood (ArcGIS)',
    'UFPZ (Urban Forest Priority Zone)',
    'HisDis (Historical Disinvestment)',
    'EJ Flag',
    'EJ #',
    'Available Area (sqm)',
    'TES (Census block)',
    'Canopy Percentage (ArcGIS)',
    'Type of Property'
]

# Create Back End Dataframe
Front_Facing_df = new_Full_df[selected_columns].copy()

# Rename columns
new_column_names = {
    'Canopy Percentage (ArcGIS)': 'Canopy Coverage (Parcel)'
}

Front_Facing_df.rename(columns=new_column_names, inplace=True)

# Prep for writing to Google Sheet
sheet = client.open('Yardtree Planting Progress Database Neighborwoods')
Front_Facing = sheet.worksheet('Requested Trees')

# Get data from Requested Trees Sheet
existing_headers = Front_Facing.row_values(1)
existing_data = Front_Facing.get_all_values()
existing_df = pd.DataFrame(existing_data[1:], columns = existing_headers)

# Get columns right
for col in existing_headers:
    if col not in Front_Facing_df.columns:
        Front_Facing_df[col] = None

Front_Facing_df = Front_Facing_df[existing_headers]

# Replace NaN and infinity values with None
Front_Facing_df = Front_Facing_df.replace({np.nan: None, np.inf: None, -np.inf: None})

# Add Not Contacted for Status
Front_Facing_df['Status'] = '1: Not Contacted'

# Convert DataFrame to a list of lists, excluding the header
data_list = Front_Facing_df.values.tolist()

# Find the first empty row in the "Input Date" column
input_date_col_idx = existing_headers_slice.index("Input Date")
start_row = next((idx for idx, row in enumerate(existing_data[1:], start=2) if not row[input_date_col_idx]), len(existing_data) + 1)

# Prepare the range for updating (starting at column A to column Z)
start_col = 'A'
end_col = multiple_letters_list[len(data_list[0])- 1]
range_to_update = f'{start_col}{start_row}:{end_col}{start_row + len(data_list) - 1}'

# Append the data to the Google Sheet without the header
Front_Facing.update(range_name=range_to_update, values=data_list, value_input_option='USER_ENTERED')